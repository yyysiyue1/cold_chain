# cold_chain/models/salmon_gbr/train_salmon_model.py

import pandas as pd
import numpy as np
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import matplotlib.pyplot as plt
import warnings
import os
import joblib # ç”¨äºä¿å­˜æ¨¡å‹

# --- åˆå§‹è®¾ç½® ---
warnings.filterwarnings('ignore')
# è®¾ç½®ä¸­æ–‡å­—ä½“ï¼Œç¡®ä¿å›¾è¡¨èƒ½æ­£ç¡®æ˜¾ç¤ºä¸­æ–‡
plt.rcParams['font.sans-serif'] = ['SimHei']
plt.rcParams['axes.unicode_minus'] = False

# =====================================================================================
# âœ… æ­¥éª¤ 1: å‚æ•°é…ç½®ä¸æ•°æ®åŠ è½½
# =====================================================================================

# --- æ–‡ä»¶ä¸åˆ—åé€‚é… ---
# è¯·ç¡®ä¿è¿™ä¸ªæ•°æ®æ–‡ä»¶ä¸æœ¬è„šæœ¬åœ¨åŒä¸€ä¸ªç›®å½•ä¸‹
data_file = 'Baranyi_all_plot_data.csv'
temp_col = 'temperature'
time_col = 'time'
concentration_col = 'concentration'
target_col = 'log10_concentration'

try:
    original_data = pd.read_csv(data_file)
    # ç­›é€‰å‡ºçœŸå®æµ‹é‡æ•°æ®è¿›è¡Œè®­ç»ƒ
    original_data = original_data[original_data['type'] == 'å®æµ‹'].copy()
    # è®¡ç®—ç›®æ ‡åˆ—ï¼šæµ“åº¦çš„å¸¸ç”¨å¯¹æ•°
    original_data[target_col] = np.log10(original_data[concentration_col] + 1e-9)
    print(f"æˆåŠŸåŠ è½½å¹¶é€‚é…æ•°æ® '{data_file}'.")
except FileNotFoundError:
    print(f"é”™è¯¯ï¼šæ‰¾ä¸åˆ°æ–‡ä»¶ '{data_file}'ã€‚è¯·ç¡®ä¿å®ƒå’Œè„šæœ¬åœ¨åŒä¸€ç›®å½•ã€‚")
    exit()

# --- ç»“æœå­˜å‚¨è®¾ç½® ---
# è®­ç»ƒè¿‡ç¨‹ä¸­çš„å›¾è¡¨å’ŒæŒ‡æ ‡ä¼šä¿å­˜åœ¨è¿™ä¸ªæ–‡ä»¶å¤¹
output_dir = 'salmon_training_results'
os.makedirs(output_dir, exist_ok=True)

# ç”¨äºå­˜å‚¨æ¨¡å‹å’Œç»“æœçš„å­—å…¸
delta_models = {}
static_models = {}
static_results = []
pseudo_dynamic_results = []


# =====================================================================================
# âœ… æ­¥éª¤ 2: ä¸ºæ¯ä¸ªæ¸©åº¦ç‹¬ç«‹è®­ç»ƒæ¨¡å‹
# =====================================================================================

temps = sorted(original_data[temp_col].unique())

print("\n--- å¼€å§‹ä¸ºæ¯ä¸ªæ¸©åº¦ç‹¬ç«‹è®­ç»ƒæ¨¡å‹ ---")
for temp in temps:
    print(f"\n--- æ­£åœ¨å¤„ç†æ¸©åº¦: {temp}Â°C ---")
    temp_data = original_data[original_data[temp_col] == temp].copy()

    if len(temp_data) < 5:
        print("   æ•°æ®ç‚¹è¿‡å°‘ï¼Œè·³è¿‡ã€‚")
        continue

    # --- è®­ç»ƒâ€œå¢é‡é¢„æµ‹â€æ¨¡å‹ (Delta Model) ---
    # è¿™æ˜¯é¢„æµ‹ç³»ç»Ÿçš„æ ¸å¿ƒï¼Œé¢„æµ‹çš„æ˜¯ä¸‹ä¸€ä¸ªæ—¶é—´ç‚¹çš„æµ“åº¦ *å¢é‡*
    temp_data['prev_target'] = temp_data[target_col].shift(1)
    train_df = temp_data.dropna()

    if len(train_df) < 2:
        print(f"   ä¸ºå¢é‡æ¨¡å‹å‡†å¤‡çš„æ•°æ®ä¸è¶³ï¼Œè·³è¿‡æ¸©åº¦ {temp}Â°Cã€‚")
        continue

    X_delta = train_df[['time', 'prev_target']]
    y_delta = train_df[target_col] - train_df['prev_target']

    delta_model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)
    delta_model.fit(X_delta, y_delta)
    delta_models[temp] = delta_model
    print(f"   âœ… å¢é‡é¢„æµ‹æ¨¡å‹ (delta model) for {temp}Â°C è®­ç»ƒå®Œæˆã€‚")

    # --- è®­ç»ƒâ€œé™æ€æ‹Ÿåˆâ€æ¨¡å‹ (ç”¨äºçº¿ä¸‹éªŒè¯å¯¹æ¯”) ---
    # è¿™ä¸ªæ¨¡å‹ç›´æ¥æ ¹æ®æ—¶é—´é¢„æµ‹æµ“åº¦ï¼Œç”¨äºè¯„ä¼°å’Œç»˜å›¾
    X_static = temp_data[[time_col]]
    y_static = temp_data[target_col]

    static_model = GradientBoostingRegressor(n_estimators=100, random_state=42)
    static_model.fit(X_static, y_static)
    static_models[temp] = static_model
    print(f"   âœ… é™æ€æ‹Ÿåˆæ¨¡å‹ for {temp}Â°C è®­ç»ƒå®Œæˆã€‚")

# =====================================================================================
# âœ… æ­¥éª¤ 3: (çº¿ä¸‹éªŒè¯) ç»Ÿä¸€è¿›è¡Œé™æ€å’Œä¼ªåŠ¨æ€éªŒè¯
# =====================================================================================
print("\n--- å¼€å§‹ç»Ÿä¸€éªŒè¯æ‰€æœ‰å·²è®­ç»ƒçš„æ¨¡å‹ ---")

for temp in temps:
    if temp not in static_models or temp not in delta_models:
        continue # å¦‚æœæŸä¸ªæ¸©åº¦çš„æ¨¡å‹æ²¡è®­ç»ƒæˆåŠŸï¼Œåˆ™è·³è¿‡

    print(f"\n--- æ­£åœ¨éªŒè¯æ¸©åº¦: {temp}Â°C ---")
    temp_data = original_data[original_data[temp_col] == temp].copy()
    t_real = temp_data[time_col].values
    y_real = temp_data[target_col].values

    # --- 1. é™æ€éªŒè¯ ---
    static_model = static_models[temp]
    y_pred_static = static_model.predict(temp_data[[time_col]])
    mae_s = mean_absolute_error(y_real, y_pred_static)
    mse_s = mean_squared_error(y_real, y_pred_static)
    r2_s = r2_score(y_real, y_pred_static)
    static_results.append({'æ¸©åº¦': temp, 'MAE': mae_s, 'MSE': mse_s, 'R2': r2_s})
    print(f"   ğŸ“Š é™æ€éªŒè¯æŒ‡æ ‡: MAE={mae_s:.4f}, MSE={mse_s:.4f}, RÂ²={r2_s:.4f}")

    # --- 2. ä¼ªåŠ¨æ€éªŒè¯ ---
    # æ¨¡æ‹ŸçœŸå®é¢„æµ‹åœºæ™¯ï¼šç”¨ä¸Šä¸€ä¸ªç‚¹çš„é¢„æµ‹ç»“æœæ¥æ¨ç®—ä¸‹ä¸€ä¸ªç‚¹
    delta_model = delta_models[temp]
    pseudo_dynamic_preds = [y_real[0]] # åˆå§‹å€¼ä½¿ç”¨çœŸå®å€¼
    current_target = y_real[0]

    for i in range(len(t_real) - 1):
        t_current = t_real[i]
        X_pred_delta = np.array([[t_current, current_target]])
        predicted_delta = delta_model.predict(X_pred_delta)[0]
        next_target = current_target + predicted_delta
        pseudo_dynamic_preds.append(next_target)
        current_target = next_target # æ›´æ–°å½“å‰æµ“åº¦ä¸ºé¢„æµ‹å€¼

    pseudo_dynamic_preds = np.array(pseudo_dynamic_preds)
    mae_pd = mean_absolute_error(y_real, pseudo_dynamic_preds)
    mse_pd = mean_squared_error(y_real, pseudo_dynamic_preds)
    r2_pd = r2_score(y_real, pseudo_dynamic_preds)
    pseudo_dynamic_results.append({'æ¸©åº¦': temp, 'MAE': mae_pd, 'MSE': mse_pd, 'R2': r2_pd})
    print(f"   ğŸ“ˆ ä¼ªåŠ¨æ€éªŒè¯æŒ‡æ ‡: MAE={mae_pd:.4f}, MSE={mse_pd:.4f}, RÂ²={r2_pd:.4f}")

    # --- 3. ç»Ÿä¸€ç»˜å›¾ ---
    plt.figure(figsize=(10, 6))
    plt.scatter(t_real, y_real, color='blue', label='å®æµ‹æ•°æ®', alpha=0.7, zorder=5)
    plt.plot(t_real, y_pred_static, color='red', linestyle='--', label=f'é™æ€æ‹Ÿåˆ (RÂ²={r2_s:.2f})')
    plt.plot(t_real, pseudo_dynamic_preds, color='green', linestyle=':', label=f'ä¼ªåŠ¨æ€é¢„æµ‹ (RÂ²={r2_pd:.2f})')
    plt.title(f'æ¨¡å‹éªŒè¯å¯¹æ¯” @ {temp}Â°C')
    plt.xlabel('æ—¶é—´ (å°æ—¶)')
    plt.ylabel('å¸¸ç”¨å¯¹æ•°æµ“åº¦ (log10 CFU/g)')
    plt.legend()
    plt.grid(True, linestyle=':')
    plt.savefig(os.path.join(output_dir, f'validation_plot_{temp}C.png'))
    plt.close()

# --- ä¿å­˜æŒ‡æ ‡æ±‡æ€» ---
static_results_df = pd.DataFrame(static_results)
pseudo_dynamic_results_df = pd.DataFrame(pseudo_dynamic_results)
static_results_df.to_csv(os.path.join(output_dir, 'static_validation_metrics.csv'), index=False, encoding='utf_8_sig')
pseudo_dynamic_results_df.to_csv(os.path.join(output_dir, 'pseudo_dynamic_validation_metrics.csv'), index=False, encoding='utf_8_sig')
print("\n--- éªŒè¯æŒ‡æ ‡å’Œå¯¹æ¯”å›¾å·²ä¿å­˜è‡³æ–‡ä»¶å¤¹:", output_dir)


# =====================================================================================
# âœ… æ­¥éª¤ 4: ä¿å­˜ç”¨äºç”Ÿäº§ç¯å¢ƒçš„æ¨¡å‹
# =====================================================================================
# è¿™æ˜¯æœ€å…³é”®çš„ä¸€æ­¥ï¼šå°†è®­ç»ƒå¥½çš„ã€ç”¨äºé¢„æµ‹çš„ delta_models ä¿å­˜æˆä¸€ä¸ª pkl æ–‡ä»¶ã€‚
# ä¸»ç³»ç»Ÿå°†åŠ è½½è¿™ä¸ªæ–‡ä»¶æ¥æ‰§è¡Œé¢„æµ‹ã€‚

if delta_models:
    # æ¨¡å‹å°†ä¿å­˜åœ¨å½“å‰ç›®å½•ä¸‹
    model_filename = 'salmon_gbr_models.pkl'

    # åˆ›å»ºä¸€ä¸ªåŒ…å«æ¨¡å‹å’Œå…ƒæ•°æ®çš„å­—å…¸ï¼Œæ–¹ä¾¿æœªæ¥è¿½æº¯
    model_payload = {
        'delta_models': delta_models,
        'training_temps': list(delta_models.keys()),
        'metadata': {
            'description': 'ä¸‰æ–‡é±¼èŒè½æ€»æ•°å¢é‡é¢„æµ‹æ¨¡å‹ (æ¢¯åº¦æå‡)',
            'model_type': 'delta_prediction',
            'train_date': pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')
        }
    }

    try:
        joblib.dump(model_payload, model_filename)
        print(f"\nâœ… [æ ¸å¿ƒ] ç”Ÿäº§æ¨¡å‹å·²æˆåŠŸä¿å­˜åˆ°: {model_filename}")
    except Exception as e:
        print(f"\nâŒ ä¿å­˜ç”Ÿäº§æ¨¡å‹å¤±è´¥: {e}")
else:
    print("\nâš ï¸ æ²¡æœ‰ä»»ä½•æ¨¡å‹è¢«è®­ç»ƒæˆåŠŸï¼Œæ— æ³•ä¿å­˜ç”Ÿäº§æ¨¡å‹æ–‡ä»¶ã€‚")

print("\n--- å…¨éƒ¨æµç¨‹å®Œæˆï¼ ---")